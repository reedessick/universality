#!/usr/bin/env python

__doc__ = "a corner plot based on fancy KDEs to make them prettier"
__author__ = "reed.essick@ligo.org"

#-------------------------------------------------

import os
import numpy as np

from argparse import ArgumentParser

### non-standard libraries
from universality import utils
from universality import plot
from universality import stats

#-------------------------------------------------

KNOWN_CONDITION_TYPES = ['point', 'lower-bound', 'upper-bound']
DEFAULT_CONDITION_TYPE = 'point'

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

# required arguments
rgroup = parser.add_argument_group('required arguments')
rgroup.add_argument('columns', nargs='+', type=str,
    help='columns to plot')
rgroup.add_argument('-s', '--samples', required=True, nargs=2, default=[], type=str, action='append',
    help='e.g.: "--samples label path/to/samples.csv"')

parser.add_argument('--reference', default=[], nargs=2, type=str, action='append',
    help='e.g.: "--reference name path". path to a reference CSV that will be plotted on top of the corner plot. Can be repeated to specify multiple reference curves. \
The columns must be the same as those supplied in the input arguments. \
DEFAULT=[]')

# verbosity arguments
vgroup = parser.add_argument_group('verbosity arguments')
vgroup.add_argument('-v', '--verbose', default=False, action='store_true')
vgroup.add_argument('-V', '--Verbose', default=False, action='store_true')

# samples arguments
sgroup = parser.add_argument_group('samples-specific argument')
sgroup.add_argument('-m', '--max-num-samples', nargs=2, default=[], type=str, action='append',
    help='label max-num-samples pairs')
sgroup.add_argument('-w', '--weight-column', nargs=2, default=[], type=str, action='append',
    help='label column pairs. if provided, thie numerical values from this column will be used as weights in the KDE')
sgroup.add_argument('-W', '--weight-column-is-log', nargs=2, default=[], type=str, action='append',
    help='the label and column for samples for which this is true')
sgroup.add_argument('--invert-weight-column', nargs=2, default=[], type=str, action='append',
    help='the label and column for samples for which this is true')

# column arguments
cgroup = parser.add_argument_group('column-specific arguments')
cgroup.add_argument('-l', '--logcolumn', default=[], type=str, action='append',
    help='convert the values read in for this column to natural log. \
Can be repeated to specify multiple columns. \
DEFAULT=[]')
cgroup.add_argument('-L', '--column-label', nargs=2, default=[], type=str, action='append',
    help='replace the column name with this label in the corner plot. e.g.: \'xcol $x$\'. \
DEFAULT=[]')
cgroup.add_argument('-T', '--column-truth', nargs=2, default=[], type=str, action='append',
    help='include this as an injected value for this column. e.g: \'--column-truth xcol 5\'. \
DEFAULT=[]')

cgroup.add_argument('-r', '--column-range', nargs=3, default=[], action='append', type=str,
    help='specify the ranges used in corner.corner (eg.: "--column-range column minimum maximum"). \
Can specify ranges for multiple columns by repeating this option. \
DEFAULT will use the minimum and maximum observed sample points.')

cgroup.add_argument('-b', '--column-bandwidth', nargs=2, default=[], type=str, action='append',
    help='the bandwidths used for each column specified. We assume diagonal covariance matricies in the Gaussian kernel. \
If you do not specify a bandwidth for a column, a best-guess bandwidth will be used based on the data supplied.')

cgroup.add_argument('--column-multiplier', nargs=2, default=[], type=str, action='append',
    help='multiply the column by this number before computing statistics. This is applied when data is first read in \
(but after taking the natural log if --logcolumn is specified), meaning bandwidths and ranges should be specified in \
terms of the column times the multiplier. If no multiplier is specified for a column, that column is left unchanged.')

# conditioning arguments
Cgroup = parser.add_argument_group('arguments for conditioning on specific vaules')
Cgroup.add_argument('-c', '--condition', nargs=2, type=str, default=[], action='append',
    help='condition the KDE on a specific value. eg, "--condition m1_source 1.5"')
Cgroup.add_argument('--condition-type', nargs=2, type=str, default=[], action='append',
    help='when conditioning the KDE, treat the value as an upper or lower limit.\
Specify the column name and one of: %s. \
eg, "--condition-type m1_source lower-bound".'%(', '.join(KNOWN_CONDITION_TYPES)))

# workflow options
wgroup = parser.add_argument_group('workflow options')
wgroup.add_argument('--whiten', default=False, action='store_true',
    help='if specified, bandwidths will be interpreted as the whitened bandwidths.')
wgroup.add_argument('--num-points', default=plot.DEFAULT_NUM_POINTS, type=int,
    help='DEFAULT=%d'%plot.DEFAULT_NUM_POINTS)
wgroup.add_argument('--reflect', default=False, action='store_true',
    help='reflect the points about their boundaries within the KDE')
wgroup.add_argument('--prune', default=False, action='store_true',
    help='throw away samples that live outside the specified ranges')

wgroup.add_argument('--num-proc', default=utils.DEFAULT_NUM_PROC, type=int)

# plotting options
pgroup = parser.add_argument_group('plotting options')
pgroup.add_argument('--color', nargs=2, action='append', default=[], type=str,
    help='e.g. "--color label c"')
pgroup.add_argument('--truth-color', default=plot.DEFAULT_TRUTH_COLOR, type=str)
pgroup.add_argument('--reference-color', nargs=2, type=str, default=[], action='append',
    help='e.g.: "--reference-color name b"')

pgroup.add_argument('--level', default=[], type=float, action='append',
    help='confidence level for the contour plots. Can be repeated to specify multiple levels.')

pgroup.add_argument('--level1D', default=[], type=float, action='append',
    help='confidence level for the 1D histograms (shown with vertical lines). Can be repeated to specify multiple levels.')

pgroup.add_argument('--hist1D', default=False, action='store_true',
    help='include raw histrograms in 1D marginal panels')
pgroup.add_argument('--no-scatter', default=False, action='store_true')
pgroup.add_argument('--rotate', default=False, action='store_true',
    help='rotate the last 1D histogram')
pgroup.add_argument('--rotate-xticklabels', default=0, type=float,
    help='the number of degrees by which to rotate the xticklabels')
pgroup.add_argument('--rotate-yticklabels', default=0, type=float,
    help='the number of degrees by which to rotate the yticklabels')

pgroup.add_argument('--legend', default=False, action='store_true')
pgroup.add_argument('--include-neff', default=False, action='store_true',
    help='include an estimate of the effective number of samples as a title')

pgroup.add_argument('--reference-legend', default=False, action='store_true')

pgroup.add_argument('--filled', default=False, action='store_true',
    help='fill in the contours plotted in corner plots')

pgroup.add_argument('--figwidth', default=plot.DEFAULT_FIGWIDTH, type=float)
pgroup.add_argument('--figheight', default=plot.DEFAULT_FIGHEIGHT, type=float)

pgroup.add_argument('--grid', default=False, action='store_true')

# ouptut options
ogroup = parser.add_argument_group('output options')
ogroup.add_argument('-o', '--output-dir', default='.', type=str)
ogroup.add_argument('-t', '--tag', default='', type=str)
ogroup.add_argument('--figtype', default=[], type=str, action='append')
ogroup.add_argument('--dpi', default=plot.DEFAULT_DPI, type=float)

args = parser.parse_args()

### finish parsing

# required arguments
Ncol = len(args.columns)
assert Ncol, 'please supply at least one column'

names = [label for label, path in args.samples]
reference_names = [label for label, path in args.reference]

# set up conditioning arguments
conditions = dict((column, (float(val), DEFAULT_CONDITION_TYPE)) for column, val in args.condition)
condition_columns = conditions.keys()
Ncond = len(condition_columns)
for col in condition_columns:
    assert col not in args.columns, 'cannot condition on a column that is included in the corner plot!'

load_columns = args.columns + condition_columns

for col, condition_type in args.condition_type:
    assert col in conditions, 'specifying --condition-type for unknown column: '+col
    assert condition_type in KNOWN_CONDITION_TYPES, 'cumulative direction not understood. Must be one of: %s'%(', '.join(KNOWN_CONDITION_TYPES))
    conditions[col] = conditions[col][0], condition_type

# workflow arguments
if args.whiten and (len(names)>1):
    raise RuntimeError('cannot whiten data with more than one sample set!')

# verbosity arguments
args.verbose |= args.Verbose

# samples arguments
max_num_samples = dict((label, np.infty) for label in names)
for label, num in args.max_num_samples:
    assert label in names, 'specifying --max-num-sample for unknown sample set: '+label
    max_num_samples[label] = int(num)

weight_columns = dict((label, ([], [], [])) for label in names)
for label, column in args.weight_column:
    assert label in names, 'specifying --weight-column for unknown sample set: '+label
    weight_columns[label][0].append(column)
for label, column in args.weight_column_is_log:
    assert label in names, 'specifying --weight-column-is-log for unknown sample set: '+label
    weight_columns[label][1].append(column)
for label, column in args.invert_weight_column:
    assert label in names, 'specifying --weight-column-is-log for unknown sample set: '+label
    weight_columns[label][2].append(column)

# column arguments
rangesdict = dict()
for column, _min, _max in args.column_range:
    assert column in load_columns, 'specifying --column-range for unknown column: '+column
    rangesdict[column] = (float(_min), float(_max))

bandwidthdict = dict()
for column, b in args.column_bandwidth:
    assert column in load_columns, 'specifying --column-bandwidth for unknown column: '+column
    bandwidthdict[column] = float(b)
bandwidths = [bandwidthdict.get(col, None) for col in load_columns] ### If None, will estimate automatically with Silverman's rule of thumb (for univariate data)

multiplierdict = dict()
for column, m in args.column_multiplier:
    assert column in load_columns, 'specifying --column-multiplier for uknown column: '+column
    multiplierdict[column] = float(m)

labeldict = dict()
for column, label in args.column_label:
    assert column in args.columns, 'specifying --column-label for unknown column: '+column
    labeldict[column] = label
labels = [labeldict.get(col, '$'+col+'$') for col in args.columns]

truthdict = dict()
for column, value in args.column_truth:
    assert column in args.columns, 'specifying --column-truth for unknown column: '+column
    truthdict[column] = float(value)
truths = [truthdict.get(col, None) for col in args.columns]

# plotting options
colors = dict((label, plot.DEFAULT_COLOR1) for label in names)
for label, color in args.color:
    assert label in names, 'specifying --color for uknown sample set: '+label
    colors[label] = color

reference_colors = dict((label, plot.DEFAULT_TRUTH_COLOR) for label in reference_names)
for label, color in args.reference_color:
    assert label in reference_names, 'specifying --reference-color for unknown reference set: '+label
    reference_colors[label] = color

if not args.level:
    args.level = plot.DEFAULT_LEVELS

# ouptut options
if args.tag:
    args.tag = "_"+args.tag

if args.output_dir and (not os.path.exists(args.output_dir)):
    os.makedirs(args.output_dir)

if not args.figtype:
    args.figtype = plot.DEFAULT_FIGTYPES

#-------------------------------------------------

fig = None
global_ranges = [(np.infty, -np.infty) for _ in range(Ncol+Ncond)]

### read in data from csv and plot
for ind, (label, path) in enumerate(args.samples):
    if args.verbose:
        print('reading samples for %s from: %s'%(label, path))
    data, columns = utils.load(path, load_columns, logcolumns=args.logcolumn, max_num_samples=max_num_samples[label])

    for i, column in enumerate(load_columns): ### apply multiplicative factor based on the original column names
        if column in multiplierdict:
            data[:,i] *= multiplierdict[column]

    ranges = []
    for i, col in enumerate(args.columns):
        if rangesdict.has_key(col):
            ranges.append(rangesdict[col])
        else:
            ranges.append((np.min(data[:,i]), np.max(data[:,i])))
        global_ranges[i] = (min(ranges[i][0], global_ranges[i][0]), max(ranges[i][1], global_ranges[i][1]))

    if args.whiten:
        data, means, stds = utils.whiten(data, verbose=args.verbose)
        ranges = [((MIN-m)/s, (MAX-m)/s) for (MIN, MAX), m, s in zip(ranges, means, stds)]
        truths = [(val-m)/s if val is not None else val for val, m, s in zip(truths, means, stds)]

    if weight_columns[label][0]:
        if args.verbose:
            print('reading in non-trivial weights from: '+path)
        weights = utils.load_weights(
            path,
            weight_columns[label][0],
            logweightcolumns=weight_columns[label][1],
            invweightcolumns=weight_columns[label][2],
            max_num_samples=max_num_samples[label],
        )

    else:
        N = len(data)
        weights = np.ones(N, dtype='float')/N

    if args.prune:### throw away data that's outside the bounds
        data, weights = utils.prune(data, ranges, weights=weights)

    #--------------------

    ### updatee weights based on conditioning
    ### NOTE!: this relies on the assumption of a diagonal kernel, implying we can separate the contributions into factors
    logcond = np.zeros(len(data), dtype=float)
    for i, cond_col in enumerate(condition_columns):
        val, cond_type = conditions[cond_col]

        if args.verbose:
            print('updating weights to condition on %s=%f (%s)'%(cond_col, val, cond_type))

        ### determine bandwidth
        b = bandwidths[Ncol+i]
        if b is None:
            b = plot.silverman_bandwidth(data[:,Ncol+i], weights=weights) ### use bandwidth from overall marignal distrib
            if args.verbose:
                print('automatically selected bandwidth=%.3e for col=%s as part of conditioning'%(b, cond_col))

        ### compute update to weights based on the type of condition
        if cond_type == 'point':
            ### this way will run faster thru the loop w/in the delegation
            logcond += utils.logkde(data[:,Ncol+i], np.array([val]), b**2, num_proc=args.num_proc)

        else:
            z = (val - data[:,Ncol+i])/b
            phi = utils._cumulative_gaussian_distribution(z) ### integrate from -infty up to val for each data separately

            if cond_type == 'upper-bound': ### integrate from val down for each sample
                truth = phi > 0
                logcond[truth] += np.log(phi[truth])

                truth = np.logical_not(truth)
                logcond[truth] = -np.infty ### zero weight here

            elif cond_type == 'lower-bound': ### integrate from val up for each sample
                truth = phi < 1
                logcond[truth] += np.log(1 - phi[truth])

                truth = np.logical_not(truth)
                logcond[truth] = -np.infty ### zero weight here

            else:
                raise RuntimeError('condition type=%s not understood!'%cond_type)

    ### update the weights to include the effects of conditioning
    weights = utils.exp_weights(np.log(weights) + logcond, normalize=True)

    #--------------------

    if args.verbose:
        print('plotting')
    fig = plot.kde_corner(
        data[:,:Ncol],
        bandwidths=bandwidths[:Ncol],
        truths=truths,
        truth_color=args.truth_color,
        labels=labels,
        range=ranges,
        weights=weights,
        num_points=args.num_points,
        color=colors[label],
        reflect=args.reflect,
        verbose=args.Verbose,
        hist1D=args.hist1D,
        levels1D=args.level1D,
        levels=args.level,
        filled=args.filled,
        scatter=not args.no_scatter,
        rotate=args.rotate,
        rotate_xticklabels=args.rotate_xticklabels,
        rotate_yticklabels=args.rotate_yticklabels,
        figwidth=args.figwidth,
        figheight=args.figheight,
        fig=fig,
        grid=args.grid,
        num_proc=args.num_proc,
    )

    if args.legend:
        legend = label
        if args.include_neff:
            legend = legend+": $N_\mathrm{eff} = %.1f,\ N_\mathrm{kde} = %.1f$"%(stats.neff(weights), stats.nkde(weights))
        dy = 0.25 / args.figheight ### this seems to be a good scaling.
        fig.text(0.95, 0.95-ind*dy, legend, color=colors[label], ha='right', va='top')

### plot reference curves
for i, (label, path) in enumerate(args.reference):
    if args.verbose:
        print('reading reference curve from: '+path)
    data, _ = utils.load(path, args.columns, logcolumns=args.logcolumn)
    if args.whiten:
        for i, (m, s) in enumerate(zip(means, stds)):
            data[i,:] = (data[:,i]-m)/s

    if args.verbose:
       print('plotting')

    plot.curve_corner(
        data,
        labels=labels,
        range=global_ranges,
        color=reference_colors[label],
        verbose=args.Verbose,
        figwidth=args.figwidth,
        figheight=args.figheight,
        fig=fig,
        grid=args.grid,
        rotate_xticklabels=args.rotate_xticklabels,
        rotate_yticklabels=args.rotate_yticklabels,
    )

    if args.reference_legend:
        fig.text(0.75, 0.90-i*0.05, label, color=reference_colors[label], ha='left', va='top')

### save
plot.save('kde-corner-samples%s'%args.tag, fig, directory=args.output_dir, figtypes=args.figtype, dpi=args.dpi, verbose=args.verbose)
plot.close(fig)
