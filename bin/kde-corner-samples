#!/usr/bin/env python

"""a corner plot based on fancy KDEs to make them prettier
"""
__author__ = "Reed Essick (reed.essick@gmail.com)"

#-------------------------------------------------

import os
import numpy as np

from collections import defaultdict

from argparse import ArgumentParser

### non-standard libraries
from universality.utils import (utils, io, units)
from universality import kde
from universality import plot
from universality import stats

#-------------------------------------------------

KNOWN_CONDITION_TYPES = ['point', 'lower-bound', 'upper-bound']
DEFAULT_CONDITION_TYPE = 'point'

#-------------------------------------------------

parser = ArgumentParser(description=__doc__)

# required arguments
rgroup = parser.add_argument_group('required arguments')
rgroup.add_argument('columns', nargs='+', type=str,
    help='columns to plot')
rgroup.add_argument('-s', '--samples', required=True, nargs=2, default=[], type=str, action='append',
    help='e.g.: "--samples label path/to/samples.csv"')

parser.add_argument('--reference', default=[], nargs=2, type=str, action='append',
    help='e.g.: "--reference name path". path to a reference CSV that will be plotted on top of the corner plot. Can be repeated to specify multiple reference curves. \
The columns must be the same as those supplied in the input arguments. \
DEFAULT=[]')

# verbosity arguments
vgroup = parser.add_argument_group('verbosity arguments')
vgroup.add_argument('-v', '--verbose', default=False, action='store_true')
vgroup.add_argument('-V', '--Verbose', default=False, action='store_true')

# samples arguments
sgroup = parser.add_argument_group('samples-specific argument')
sgroup.add_argument('-m', '--max-num-samples', nargs=2, default=[], type=str, action='append',
    help='label max-num-samples pairs')
sgroup.add_argument('-w', '--weight-column', nargs=2, default=[], type=str, action='append',
    help='label column pairs. if provided, thie numerical values from this column will be used as weights in the KDE')
sgroup.add_argument('-W', '--weight-column-is-log', nargs=2, default=[], type=str, action='append',
    help='the label and column for samples for which this is true')
sgroup.add_argument('--invert-weight-column', nargs=2, default=[], type=str, action='append',
    help='the label and column for samples for which this is true')

# column arguments
cgroup = parser.add_argument_group('column-specific arguments')
cgroup.add_argument('-l', '--logcolumn', default=[], type=str, action='append',
    help='convert the values read in for this column to natural log. \
Can be repeated to specify multiple columns. \
DEFAULT=[]')
cgroup.add_argument('--logcolumn-plot-linear', default=[], type=str, action='append',
    help='construct the KDE model for the log of this column but plot the corresponding density in terms of \
the linear value. This is as opposed to --logcolumn which plots the log of the column. \
Can be repeated to specify mulitple column. \
DEFAULT=[]')

cgroup.add_argument('-L', '--column-label', nargs=2, default=[], type=str, action='append',
    help='replace the column name with this label in the corner plot. e.g.: \'xcol $x$\'. \
DEFAULT=[]')
cgroup.add_argument('-T', '--column-truth', nargs=2, default=[], type=str, action='append',
    help='include this as an injected value for this column. e.g: \'--column-truth xcol 5\'. \
DEFAULT=[]')
cgroup.add_argument('-B', '--column-band', nargs=3, default=[], type=str, action='append',
    help='shade this band of values for the specified column. eg.: "--column-band xcol 1 9"')

cgroup.add_argument('-r', '--column-range', nargs=3, default=[], action='append', type=str,
    help='specify the ranges used in corner.corner (eg.: "--column-range column minimum maximum"). \
Can specify ranges for multiple columns by repeating this option. \
DEFAULT will use the minimum and maximum observed sample points.')

cgroup.add_argument('-b', '--column-bandwidth', nargs=2, default=[], type=str, action='append',
    help='the bandwidths used for each column specified. We assume diagonal covariance matricies in the Gaussian kernel. \
If you do not specify a bandwidth for a column, a best-guess bandwidth will be used based on the data supplied.')

cgroup.add_argument('--column-multiplier', nargs=2, default=[], type=str, action='append',
    help='multiply the column by this number before computing statistics. This is applied when data is first read in \
(but after taking the natural log if --logcolumn or --logcolumn-plot-linear are specified), meaning bandwidths and \
ranges should be specified in terms of the column times the multiplier. \
If no multiplier is specified for a column, that column is left unchanged.')
cgroup.add_argument('--column-shift', nargs=2, default=[], type=str, action='append',
    help='subtract this number from the column before computing statistics. This is applied when data is first read in\
(but after taking hte natural log if --logcolumn or --logcolumn-plot-linear are specified and after --column-multiplier is applied), meaning bandwidths and ranges should be specified in terms of the column times the multiplier minus the shift. \
If no shift is specified for a column that column is left unchanged.')

# conditioning arguments
Cgroup = parser.add_argument_group('arguments for conditioning on specific vaules')

Cgroup.add_argument('-c', '--condition', nargs=3, type=str, default=[], action='append',
    help='condition the KDE on a specific value. eg, "--condition samples_nickname m1_source 1.5"')
Cgroup.add_argument('--condition-type', nargs=3, type=str, default=[], action='append',
    help='when conditioning the KDE, treat the value as an upper or lower limit.\
Specify the column name and one of: %s. \
eg, "--condition-type samples_nickname m1_source lower-bound".'%(', '.join(KNOWN_CONDITION_TYPES)))

# workflow options
wgroup = parser.add_argument_group('workflow options')
wgroup.add_argument('--whiten', default=False, action='store_true',
    help='if specified, bandwidths will be interpreted as the whitened bandwidths.')
wgroup.add_argument('--num-points', default=plot.DEFAULT_NUM_POINTS, type=int,
    help='DEFAULT=%d'%plot.DEFAULT_NUM_POINTS)
wgroup.add_argument('--reflect', default=False, action='store_true',
    help='reflect the points about their boundaries within the KDE')
wgroup.add_argument('--prune', default=False, action='store_true',
    help='throw away samples that live outside the specified ranges')

wgroup.add_argument('--num-proc', default=utils.DEFAULT_NUM_PROC, type=int)

# plotting options
pgroup = parser.add_argument_group('plotting options')
pgroup.add_argument('--color', nargs=2, action='append', default=[], type=str,
    help='e.g. "--color label c"')
pgroup.add_argument('--alpha', nargs=2, action='append', default=[], type=str,
    help='e.g. "--alpha label 0.5"')
pgroup.add_argument('--filled-alpha', nargs=2, action='append', default=[], type=str,
    help='e.g. "--filled-alpha label 0.5"')

pgroup.add_argument('--truth-color', default=plot.DEFAULT_TRUTH_COLOR, type=str)
pgroup.add_argument('--truth-alpha', default=plot.DEFAULT_ALPHA, type=float)
pgroup.add_argument('--truth-linestyle', default=plot.DEFAULT_LINESTYLE, type=str)

pgroup.add_argument('--band-color', default=None, type=str)
pgroup.add_argument('--band-alpha', default=plot.DEFAULT_LIGHT_ALPHA, type=str)

pgroup.add_argument('--reference-color', nargs=2, type=str, default=[], action='append',
    help='e.g.: "--reference-color name b"')

pgroup.add_argument('--level', default=[], type=float, action='append',
    help='confidence level for the contour plots. Can be repeated to specify multiple levels.')

pgroup.add_argument('--level1D', default=[], type=float, action='append',
    help='confidence level for the 1D histograms (shown with vertical lines). Can be repeated to specify multiple levels.')

pgroup.add_argument('--hist1D', default=False, action='store_true',
    help='include raw histrograms in 1D marginal panels')
pgroup.add_argument('--no-scatter', default=False, action='store_true')
pgroup.add_argument('--rotate', default=False, action='store_true',
    help='rotate the last 1D histogram')
pgroup.add_argument('--rotate-xticklabels', default=0, type=float,
    help='the number of degrees by which to rotate the xticklabels')
pgroup.add_argument('--rotate-yticklabels', default=0, type=float,
    help='the number of degrees by which to rotate the yticklabels')

pgroup.add_argument('--legend', default=False, action='store_true')
pgroup.add_argument('--include-neff', default=False, action='store_true',
    help='include an estimate of the effective number of samples as a title')

pgroup.add_argument('--reference-legend', default=False, action='store_true')

pgroup.add_argument('--filled', default=[], type=str, action='append',
    help='fill in the contours plotted in corner plots')
pgroup.add_argument('--filled1D', default=[], type=str, action='append',
    help='fill in the 1D distributions plotted along the diagonal')

pgroup.add_argument('--figwidth', default=plot.DEFAULT_FIGWIDTH, type=float)
pgroup.add_argument('--figheight', default=plot.DEFAULT_FIGHEIGHT, type=float)

pgroup.add_argument('--grid', default=False, action='store_true')

# ouptut options
ogroup = parser.add_argument_group('output options')
ogroup.add_argument('-o', '--output-dir', default='.', type=str)
ogroup.add_argument('-t', '--tag', default='', type=str)
ogroup.add_argument('--figtype', default=[], type=str, action='append')
ogroup.add_argument('--dpi', default=plot.DEFAULT_DPI, type=float)

args = parser.parse_args()

### finish parsing

# required arguments
Ncol = len(args.columns)
assert Ncol, 'please supply at least one column'

names = [label for label, path in args.samples]
reference_names = [label for label, path in args.reference]

# set up conditioning arguments
conditions = defaultdict(dict)
for name, column, val in args.condition:
    assert name in names, 'specifying --condition for unknown sample set: '+name
    conditions[name].update({column: (float(val), DEFAULT_CONDITION_TYPE)})

condition_columns = dict((name, conditions[name].keys()) for name in names)

all_condition_columns = []
for name in names:
    all_condition_columns += condition_columns[name]
all_condition_columns = sorted(set(all_condition_columns))

Ncond = len(all_condition_columns)
for col in all_condition_columns:
    assert col not in args.columns, 'cannot condition on a column that is included in the corner plot!'

load_columns = args.columns + all_condition_columns

for name, col, condition_type in args.condition_type:
    assert name in names, 'specifying --condition-type for unknown sample set: '+name
    assert col in conditions[name], 'specifying --condition-type for unknown column: '+col
    assert condition_type in KNOWN_CONDITION_TYPES, 'cumulative direction not understood. Must be one of: %s'%(', '.join(KNOWN_CONDITION_TYPES))
    conditions[name][col] = conditions[name][col][0], condition_type

# workflow arguments
if args.whiten and (len(names)>1):
    raise RuntimeError('cannot whiten data with more than one sample set!')

# verbosity arguments
args.verbose |= args.Verbose

# samples arguments
max_num_samples = dict((label, np.infty) for label in names)
for label, num in args.max_num_samples:
    assert label in names, 'specifying --max-num-sample for unknown sample set: '+label
    max_num_samples[label] = int(num)

weight_columns = dict((label, ([], [], [])) for label in names)
for label, column in args.weight_column:
    assert label in names, 'specifying --weight-column for unknown sample set: '+label
    weight_columns[label][0].append(column)
for label, column in args.weight_column_is_log:
    assert label in names, 'specifying --weight-column-is-log for unknown sample set: '+label
    weight_columns[label][1].append(column)
for label, column in args.invert_weight_column:
    assert label in names, 'specifying --invert-weight-column for unknown sample set: '+label
    weight_columns[label][2].append(column)

# column arguments
rangesdict = dict()
for column, _min, _max in args.column_range:
    assert column in load_columns, 'specifying --column-range for unknown column: '+column
    rangesdict[column] = (float(_min), float(_max))

bandwidthdict = dict()
for column, b in args.column_bandwidth:
    assert column in load_columns, 'specifying --column-bandwidth for unknown column: '+column
    bandwidthdict[column] = float(b)
bandwidths = [bandwidthdict.get(col, None) for col in load_columns] ### If None, will estimate automatically with Silverman's rule of thumb (for univariate data)

multiplierdict = dict()
for column, m in args.column_multiplier:
    assert column in load_columns, 'specifying --column-multiplier for uknown column: '+column
    if hasattr(units, m):
        multiplierdict[column] = getattr(units, m)
    else:
        multiplierdict[column] = float(m)

shiftdict = dict()
for column, s in args.column_shift:
    assert column in load_columns, 'specifying --column-shift for unknown column: '+column
    if hasattr(units, s):
        shiftdict[column] = getattr(units, s)
    else:
        shiftdict[column] = float(s)

labeldict = dict()
for column, label in args.column_label:
    assert column in args.columns, 'specifying --column-label for unknown column: '+column
    labeldict[column] = label
labels = [labeldict.get(col, '$'+col+'$') for col in args.columns]

truthdict = defaultdict(list)
for column, value in args.column_truth:
    assert column in args.columns, 'specifying --column-truth for unknown column: '+column
    truthdict[column].append(float(value))
truths = [truthdict.get(col, None) for col in args.columns]

banddict = defaultdict(list)
for column, m, M in args.column_band:
    assert column in args.columns, 'specifying --column-band for unknown column: '+column
    banddict[column].append((float(m), float(M)))
bands = [banddict.get(col, None) for col in args.columns]

# plotting options
colors = dict((label, plot.DEFAULT_COLOR1) for label in names)
for label, color in args.color:
    assert label in names, 'specifying --color for uknown sample set: '+label
    colors[label] = color

alphas = dict((label, plot.DEFAULT_ALPHA) for label in names)
for label, alpha in args.alpha:
    assert label in names, 'specifying --alpha for unknown samples set: '+label
    alphas[label] = float(alpha)

for label in args.filled:
    assert label in names, 'specifying --filled for unknown set: '+label
for label in args.filled1D:
    assert label in names, 'specifying --filled1D for unknown set: '+label

filled_alphas = dict((label, plot.DEFAULT_ALPHA) for label in names)
for label, alpha in args.filled_alpha:
    assert label in names, 'specifying --filled-alpha for unknown set: '+label
    filled_alphas[label] = float(alpha)

reference_colors = dict((label, plot.DEFAULT_TRUTH_COLOR) for label in reference_names)
for label, color in args.reference_color:
    assert label in reference_names, 'specifying --reference-color for unknown reference set: '+label
    reference_colors[label] = color

if not args.level:
    args.level = plot.DEFAULT_LEVELS

# ouptut options
if args.tag:
    args.tag = "_"+args.tag

if args.output_dir and (not os.path.exists(args.output_dir)):
    os.makedirs(args.output_dir)

if not args.figtype:
    args.figtype = plot.DEFAULT_FIGTYPES

#-------------------------------------------------

fig = None
global_ranges = [(np.infty, -np.infty) for _ in range(Ncol+Ncond)]

### read in data from csv and plot
for ind, (label, path) in enumerate(args.samples):
    if args.verbose:
        print('reading samples for %s from: %s'%(label, path))
    data, columns = io.load(
        path,
        load_columns,
        logcolumns=args.logcolumn + args.logcolumn_plot_linear,
        max_num_samples=max_num_samples[label],
    )

    for i, column in enumerate(load_columns): ### apply multiplicative factor based on the original column names
        if column in multiplierdict:
            data[:,i] *= multiplierdict[column]

        if column in shiftdict:
            data[:,i] -= shiftdict[column]

    ranges = []
    for i, col in enumerate(args.columns):
        if rangesdict.has_key(col):
            ranges.append(rangesdict[col])
        else:
            ranges.append((np.min(data[:,i]), np.max(data[:,i])))
        global_ranges[i] = (min(ranges[i][0], global_ranges[i][0]), max(ranges[i][1], global_ranges[i][1]))

    if args.whiten:
        data, means, stds = utils.whiten(data, verbose=args.verbose)
        these_ranges = [((MIN-m)/s, (MAX-m)/s) for (MIN, MAX), m, s in zip(ranges, means, stds)]
        these_truths = [[(v-m)/s for v in val] if val is not None else val for val, m, s in zip(truths, means, stds)]
        these_bands = [[((v-m)/s, (V-m)/s) for v, V in val] if val is not None else val for val, m, s in zip(bands, means, stds)]
    else:
        these_ranges = ranges
        if ind+1 == len(args.samples): ### only plot truths if this is the last data set (assuming they aren't auto-scaled)
            these_truths = truths
            these_bands = bands
        else:
            these_truths = None
            these_bands = None

    if weight_columns[label][0]:
        if args.verbose:
            print('reading in non-trivial weights from: '+path)
        weights = io.load_weights(
            path,
            weight_columns[label][0],
            logweightcolumns=weight_columns[label][1],
            invweightcolumns=weight_columns[label][2],
            max_num_samples=max_num_samples[label],
        )

    else:
        N = len(data)
        weights = np.ones(N, dtype='float')/N

    if args.prune:### throw away data that's outside the bounds
        data, weights = utils.prune(data, these_ranges, weights=weights)

    #--------------------

    ### updatee weights based on conditioning
    ### NOTE!: this relies on the assumption of a diagonal kernel, implying we can separate the contributions into factors
    logcond = np.zeros(len(data), dtype=float)
    for i, cond_col in enumerate(condition_columns[label]):
        val, cond_type = conditions[label][cond_col]

        if args.verbose:
            print('updating weights to condition on %s=%f (%s)'%(cond_col, val, cond_type))

        ### determine bandwidth
        b = bandwidths[columns.index(cond_col)]
        if b is None:
            b = plot.silverman_bandwidth(data[:,Ncol+i], weights=weights) ### use bandwidth from overall marignal distrib
            if args.verbose:
                print('automatically selected bandwidth=%.3e for col=%s as part of conditioning'%(b, cond_col))

        ### compute update to weights based on the type of condition
        if cond_type == 'point':
            ### this way will run faster thru the loop w/in the delegation
            logcond += kde.logkde(data[:,Ncol+i], np.array([val]), b**2, num_proc=args.num_proc)

        else:
            z = (val - data[:,Ncol+i])/b
            phi = kde.cumulative_gaussian_distribution(z) ### integrate from -infty up to val for each data separately

            if cond_type == 'upper-bound': ### integrate from val down for each sample
                truth = phi > 0
                logcond[truth] += np.log(phi[truth])

                truth = np.logical_not(truth)
                logcond[truth] = -np.infty ### zero weight here

            elif cond_type == 'lower-bound': ### integrate from val up for each sample
                truth = phi < 1
                logcond[truth] += np.log(1 - phi[truth])

                truth = np.logical_not(truth)
                logcond[truth] = -np.infty ### zero weight here

            else:
                raise RuntimeError('condition type=%s not understood!'%cond_type)

    ### update the weights to include the effects of conditioning
    weights = utils.exp_weights(np.log(weights) + logcond, normalize=True)

    #--------------------

    if args.verbose:
        print('plotting')
    fig = plot.kde_corner(
        data[:,:Ncol],
        bandwidths=bandwidths[:Ncol],
        scales=['exp' if col in args.logcolumn_plot_linear else 'linear' for col in args.columns],
        truths=these_truths,
        truth_color=args.truth_color,
        truth_alpha=args.truth_alpha,
        truth_linestyle=args.truth_linestyle,
        bands=these_bands,
        band_color=args.band_color,
        band_alpha=args.band_alpha,
        labels=labels,
        range=these_ranges,
        weights=weights,
        num_points=args.num_points,
        color=colors[label],
        alpha=alphas[label],
        reflect=args.reflect,
        verbose=args.Verbose,
        hist1D=args.hist1D,
        levels1D=args.level1D,
        levels=args.level,
        filled=label in args.filled,
        filled1D=label in args.filled1D,
        filled_alpha=filled_alphas[label],
        scatter=not args.no_scatter,
        rotate=args.rotate,
        rotate_xticklabels=args.rotate_xticklabels,
        rotate_yticklabels=args.rotate_yticklabels,
        figwidth=args.figwidth,
        figheight=args.figheight,
        fig=fig,
        grid=args.grid,
        num_proc=args.num_proc,
    )

    if args.legend:
        legend = label
        if args.include_neff:
            legend = legend+": $N_\mathrm{eff} = %.1f,\ N_\mathrm{kde} = %.1f$"%(stats.neff(weights), stats.nkde(weights))
        dy = 0.25 / args.figheight ### this seems to be a good scaling.
        fig.text(0.95, 0.95-ind*dy, legend, color=colors[label], alpha=alphas[label], ha='right', va='top')

### plot reference curves
for i, (label, path) in enumerate(args.reference):
    if args.verbose:
        print('reading reference curve from: '+path)
    data, _ = io.load(path, args.columns, logcolumns=args.logcolumn)
    if args.whiten:
        for i, (m, s) in enumerate(zip(means, stds)):
            data[i,:] = (data[:,i]-m)/s

    if args.verbose:
       print('plotting')

    plot.curve_corner(
        data,
        labels=labels,
        range=global_ranges,
        color=reference_colors[label],
        verbose=args.Verbose,
        figwidth=args.figwidth,
        figheight=args.figheight,
        fig=fig,
        grid=args.grid,
        rotate_xticklabels=args.rotate_xticklabels,
        rotate_yticklabels=args.rotate_yticklabels,
    )

    if args.reference_legend:
        fig.text(0.75, 0.90-i*0.05, label, color=reference_colors[label], ha='left', va='top')

### save
plot.save('kde-corner-samples%s'%args.tag, fig, directory=args.output_dir, figtypes=args.figtype, dpi=args.dpi, verbose=args.verbose)
plot.close(fig)
